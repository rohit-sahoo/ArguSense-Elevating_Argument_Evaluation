{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Setting the version number for this configuration\nVER = 14\n\n# Loading tokens from a specified directory\nLOAD_TOKENS_FROM = '../input/tf-longformer-v12'\n\n# Loading the model from a specified directory\nLOAD_MODEL_FROM = '../input/tflongformerv14'\n\n# Specifying the path where the downloaded model will be saved\nDOWNLOADED_MODEL_PATH = '../input/tf-longformer-v12'\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom transformers import *","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:40:31.369365Z","iopub.execute_input":"2023-08-09T23:40:31.369652Z","iopub.status.idle":"2023-08-09T23:40:44.364571Z","shell.execute_reply.started":"2023-08-09T23:40:31.369622Z","shell.execute_reply":"2023-08-09T23:40:44.363528Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Enabling automatic mixed precision for better GPU memory utilization\ntf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n\n# Loading the tokenizer from the downloaded model path\ntokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:40:44.366881Z","iopub.execute_input":"2023-08-09T23:40:44.367148Z","iopub.status.idle":"2023-08-09T23:40:44.570713Z","shell.execute_reply.started":"2023-08-09T23:40:44.367116Z","shell.execute_reply":"2023-08-09T23:40:44.569731Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Specifying the maximum length for tokens\nMAX_LEN = 1024\n\n# Loading target data from the specified directory and file for the given maximum length\ntargets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n\n# Loading training tokens from the specified directory and file for the given maximum length\ntrain_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n\n# Loading attention data from the specified directory and file for the given maximum length\ntrain_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n\n# Printing a message to indicate that NER tokens have been loaded\nprint('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:40:44.572184Z","iopub.execute_input":"2023-08-09T23:40:44.572499Z","iopub.status.idle":"2023-08-09T23:40:56.232757Z","shell.execute_reply.started":"2023-08-09T23:40:44.572463Z","shell.execute_reply":"2023-08-09T23:40:56.231837Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Loaded NER tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a function to build the model\ndef build_model():\n    # Define inputs for tokens and attention masks with the specified shape and data type\n    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name='tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name='attention', dtype=tf.int32)\n    \n    # Load the model configuration from the downloaded model's config.json file\n    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH + '/config.json') \n    \n    # Load the pre-trained model using the loaded configuration\n    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH + '/tf_model.h5', config=config)\n    \n    # Pass the inputs through the backbone model\n    x = backbone(tokens, attention_mask=attention)\n    \n    # Apply a dense layer with ReLU activation\n    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n    \n    # Apply another dense layer with softmax activation for classification\n    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n    \n    # Create the final model using inputs and outputs\n    model = tf.keras.Model(inputs=[tokens, attention], outputs=x)\n    \n    # Compile the model with specified optimizer, loss function, and metrics\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n                  loss=[tf.keras.losses.CategoricalCrossentropy()],\n                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n    \n    return model\n\ntf.keras.utils.get_custom_objects()[\"swish\"] = tf.keras.activations.swish\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:56:57.660563Z","iopub.execute_input":"2023-08-09T23:56:57.661571Z","iopub.status.idle":"2023-08-09T23:56:57.674718Z","shell.execute_reply.started":"2023-08-09T23:56:57.661516Z","shell.execute_reply":"2023-08-09T23:56:57.673610Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# Creating an instance of the model using the build_model() function\nmodel = build_model()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:56:59.484829Z","iopub.execute_input":"2023-08-09T23:56:59.485187Z","iopub.status.idle":"2023-08-09T23:57:33.232777Z","shell.execute_reply.started":"2023-08-09T23:56:59.485148Z","shell.execute_reply":"2023-08-09T23:57:33.231597Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# Loading pre-trained weights into the model from the specified path\nmodel.load_weights('/kaggle/input/tflongformerv14/long_v14.h5')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:58:20.224793Z","iopub.execute_input":"2023-08-09T23:58:20.225154Z","iopub.status.idle":"2023-08-09T23:58:26.121181Z","shell.execute_reply.started":"2023-08-09T23:58:20.225117Z","shell.execute_reply":"2023-08-09T23:58:26.120272Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# Creating arrays to store test tokens and attention masks with zeros\n# The shape of the arrays is (1, MAX_LEN), where MAX_LEN is the specified maximum token length\ntest_tokens = np.zeros((1, MAX_LEN), dtype='int32')\ntest_attention = np.zeros((1, MAX_LEN), dtype='int32')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:58:26.122944Z","iopub.execute_input":"2023-08-09T23:58:26.123340Z","iopub.status.idle":"2023-08-09T23:58:26.128653Z","shell.execute_reply.started":"2023-08-09T23:58:26.123291Z","shell.execute_reply":"2023-08-09T23:58:26.127548Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \nn = \"0FB0700DAF44\"\n#name = f'../input/feedback-prize-2021/test/{n}.txt'\n\ntext_to_write = '''While it may be true that the Mason City government ought to devote more money to riverside recreational facilities, this author's argument does not make a cogent case for increased resources based on river use. It is easy to understand why city residents would want a cleaner river, but this argument is rife with holes and assumptions, and thus, not strong enough to lead to increased funding.\nCiting surveys of city residents, the author reports city resident's love of water sports. It is not clear, however, the scope and validity of that survey. For example, the survey could have asked residents if they prefer using the river for water sports or would like to see a hydroelectric dam built, which may have swayed residents toward river sports. The sample may not have been representative of city residents, asking only those residents who live upon the river. The survey may have been 10 pages long, with 2 questions dedicated to river sports. We just do not know. Unless the survey is fully representative, valid, and reliable, it can not be used to effectively back the author's argument.\nAdditionally, the author implies that residents do not use the river for swimming, boating, and fishing, despite their professed interest, because the water is polluted and smelly. While a polluted, smelly river would likely cut down on river sports, a concrete connection between the resident's lack of river use and the river's current state is not effectively made. Though there have been complaints, we do not know if there have been numerous complaints from a wide range of people, or perhaps from one or two individuals who made numerous complaints. To strengthen his/her argument, the author would benefit from implementing a normed survey asking a wide range of residents why they do not currently use the river.\nBuilding upon the implication that residents do not use the river due to the quality of the river's water and the smell, the author suggests that a river clean up will result in increased river usage. If the river's water quality and smell result from problems which can be cleaned, this may be true. For example, if the decreased water quality and aroma is caused by pollution by factories along the river, this conceivably could be remedied. But if the quality and\naroma results from the natural mineral deposits in the water or surrounding rock, this may not be true. There are some bodies of water which emit a strong smell of sulphur due to the geography of the area. This is not something likely to be affected by a clean-up. Consequently, a river clean up may have no impact upon river usage. Regardless of whether the river's quality is able to be improved or not, the author does not effectively show a connection between water quality and river usage.\nA clean, beautiful, safe river often adds to a city's property values, leads to increased tourism and revenue from those who come to take advantage of the river, and a better overall quality of life for residents. For these reasons, city government may decide to invest in improving riverside recreational facilities.\nHowever, this author's argument is not likely significantly persuade the city goverment to allocate increased funding.\n'''\n# Tokenizing the input text and saving tokens and attention masks in arrays\ntokens = tokenizer.encode_plus(\n    text_to_write,              # Input text to tokenize\n    max_length=MAX_LEN,         # Maximum length of tokens\n    padding='max_length',       # Pad tokens to the maximum length\n    truncation=True,            # Truncate tokens if needed\n    return_offsets_mapping=True # Return offsets mapping for future reference\n)\n\n# Storing the tokenized input and attention mask in the test token arrays\ntest_tokens[0,] = tokens['input_ids']       # Store tokenized input\ntest_attention[0,] = tokens['attention_mask']  # Store attention mask","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:58:26.130000Z","iopub.execute_input":"2023-08-09T23:58:26.130351Z","iopub.status.idle":"2023-08-09T23:58:26.151459Z","shell.execute_reply.started":"2023-08-09T23:58:26.130305Z","shell.execute_reply":"2023-08-09T23:58:26.150465Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# Using the trained model to make predictions on the test tokens and attention masks\np = model.predict(\n    [test_tokens, test_attention],  # Input data for prediction\n    batch_size=16,                  # Batch size for inference\n    verbose=2                       # Display progress information\n)\n\n# Printing the shape of the predictions array\nprint('Test predictions shape:', p.shape)\n\n# Finding the indices of the highest predicted values along the last axis\ntest_preds = np.argmax(p, axis=-1)\n\n# Returning the array of predicted labels\ntest_preds\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:58:26.153543Z","iopub.execute_input":"2023-08-09T23:58:26.154092Z","iopub.status.idle":"2023-08-09T23:58:53.792904Z","shell.execute_reply.started":"2023-08-09T23:58:26.154041Z","shell.execute_reply":"2023-08-09T23:58:53.792122Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"1/1 - 28s\nTest predictions shape: (1, 1024, 15)\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"array([[ 2,  3,  3, ..., 14, 14, 14]])"},"metadata":{}}]},{"cell_type":"code","source":"# Creating a reverse mapping of target labels for interpretation\ntarget_map_rev = {\n    0: 'Lead', 1: 'Position', 2: 'Evidence', 3: 'Claim', 4: 'Concluding Statement',\n    5: 'Counterclaim', 6: 'Rebuttal', 7: 'blank'\n}\n\n# Initializing a list to store all predictions\nall_predictions = []\n\ntxt = text_to_write\ntokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                       truncation=True, return_offsets_mapping=True)\n\n# Extracting offset mappings to determine word positions\noff = tokens['offset_mapping']\n\n# Determining word positions in characters\nw = []\nblank = True\nfor i in range(len(txt)):\n    if (txt[i] != ' ') & (txt[i] != '\\n') & (txt[i] != '\\xa0') & (txt[i] != '\\x85') & (blank == True):\n        w.append(i)\n        blank = False\n    elif (txt[i] == ' ') | (txt[i] == '\\n') | (txt[i] == '\\xa0') | (txt[i] == '\\x85'):\n        blank = True\n\nw.append(1e6)\n\n# Mapping from tokens to words using offset mappings\nword_map = -1 * np.ones(MAX_LEN, dtype='int32')\nw_i = 0\n\nfor i in range(len(off)):\n    if off[i][1] == 0:\n        continue\n    while off[i][0] >= w[w_i + 1]:\n        w_i += 1\n    word_map[i] = int(w_i)\n\n# Processing token predictions and mapping to words\npred = test_preds[0,] / 2.0\n\ni = 0\nwhile i < MAX_LEN:\n    prediction = []\n    start = pred[i]\n    if start in [0, 1, 2, 3, 4, 5, 6, 7]:\n        prediction.append(word_map[i])\n        i += 1\n        if i >= MAX_LEN:\n            break\n        while pred[i] == start + 0.5:\n            if word_map[i] not in prediction:\n                prediction.append(word_map[i])\n            i += 1\n            if i >= MAX_LEN:\n                break\n    else:\n        i += 1\n    prediction = [x for x in prediction if x != -1]\n    if len(prediction) > 4:\n        all_predictions.append((n, target_map_rev[int(start)], ' '.join([str(x) for x in prediction])))\n\n# Creating a DataFrame from the collected predictions\ndf = pd.DataFrame(all_predictions)\ndf.columns = ['id', 'discourse_type', 'predictionstring']\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:58:53.793903Z","iopub.execute_input":"2023-08-09T23:58:53.794138Z","iopub.status.idle":"2023-08-09T23:58:53.824882Z","shell.execute_reply.started":"2023-08-09T23:58:53.794107Z","shell.execute_reply":"2023-08-09T23:58:53.823773Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# Extracting the 'id' column from the DataFrame\nid_num = df['id']\n\n# Initializing variables for tracking\ncounter = 0\nlast_char_index = -1\ndiscourse_start = []\ndiscourse_end = []\ndiscourse_text = []\ndiscourse_id = []\n\n# Looping through each 'id' in the DataFrame\nfor ids in id_num:\n    first_prediction_string = df['predictionstring'].iloc[counter]\n\n    text_no = first_prediction_string.split(' ')\n    text_start = int(text_no[0])\n    text_end = int(text_no[-1])\n\n    words = txt.split()\n\n    # Extracting the text within the predicted discourse span\n    text = words[text_start:text_end + 1]\n    text2 = words[0:text_start]\n\n    # Calculating the character index for the start of the discourse span\n    current_word_char = len(\" \".join(text2))\n    if current_word_char != 0:\n        current_word_char += 1\n    start_char_index = 0 + current_word_char\n\n    # Calculating the character index for the end of the discourse span\n    total_chars = len(\" \".join(text))\n    last_char_index = start_char_index + total_chars\n\n    # Appending the calculated values to respective lists\n    discourse_text.append(\" \".join(text))\n    discourse_start.append(start_char_index)\n    discourse_end.append(last_char_index)\n    discourse_id.append(counter)\n    counter += 1\n\n# Adding the calculated values as new columns to the DataFrame\ndf['discourse_start'] = discourse_start\ndf['discourse_end'] = discourse_end\ndf['discourse_text'] = discourse_text\ndf['discourse_id'] = discourse_id\ndf","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:58:53.826327Z","iopub.execute_input":"2023-08-09T23:58:53.826595Z","iopub.status.idle":"2023-08-09T23:58:53.850167Z","shell.execute_reply.started":"2023-08-09T23:58:53.826564Z","shell.execute_reply":"2023-08-09T23:58:53.849273Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"             id discourse_type  \\\n0  0FB0700DAF44       Position   \n1  0FB0700DAF44          Claim   \n2  0FB0700DAF44          Claim   \n3  0FB0700DAF44       Evidence   \n4  0FB0700DAF44          Claim   \n5  0FB0700DAF44       Evidence   \n6  0FB0700DAF44       Evidence   \n\n                                    predictionstring  discourse_start  \\\n0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                0   \n1  67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 8...              396   \n2  186 187 188 189 190 191 192 193 194 195 196 19...             1099   \n3  213 214 215 216 217 218 219 220 221 222 223 22...             1280   \n4  303 304 305 306 307 308 309 310 311 312 313 31...             1820   \n5  339 340 341 342 343 344 345 346 347 348 349 35...             2021   \n6  403 404 405 406 407 408 409 410 411 412 413 41...             2391   \n\n   discourse_end                                     discourse_text  \\\n0            395  While it may be true that the Mason City gover...   \n1            551  Citing surveys of city residents, the author r...   \n2           1279  Additionally, the author implies that resident...   \n3           1819  While a polluted, smelly river would likely cu...   \n4           2020  Building upon the implication that residents d...   \n5           2390  If the river's water quality and smell result ...   \n6           2630  There are some bodies of water which emit a st...   \n\n   discourse_id  \n0             0  \n1             1  \n2             2  \n3             3  \n4             4  \n5             5  \n6             6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_type</th>\n      <th>predictionstring</th>\n      <th>discourse_start</th>\n      <th>discourse_end</th>\n      <th>discourse_text</th>\n      <th>discourse_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0FB0700DAF44</td>\n      <td>Position</td>\n      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n      <td>0</td>\n      <td>395</td>\n      <td>While it may be true that the Mason City gover...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 8...</td>\n      <td>396</td>\n      <td>551</td>\n      <td>Citing surveys of city residents, the author r...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>186 187 188 189 190 191 192 193 194 195 196 19...</td>\n      <td>1099</td>\n      <td>1279</td>\n      <td>Additionally, the author implies that resident...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>213 214 215 216 217 218 219 220 221 222 223 22...</td>\n      <td>1280</td>\n      <td>1819</td>\n      <td>While a polluted, smelly river would likely cu...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>303 304 305 306 307 308 309 310 311 312 313 31...</td>\n      <td>1820</td>\n      <td>2020</td>\n      <td>Building upon the implication that residents d...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>339 340 341 342 343 344 345 346 347 348 349 35...</td>\n      <td>2021</td>\n      <td>2390</td>\n      <td>If the river's water quality and smell result ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>403 404 405 406 407 408 409 410 411 412 413 41...</td>\n      <td>2391</td>\n      <td>2630</td>\n      <td>There are some bodies of water which emit a st...</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Classification","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport warnings,transformers,logging,torch\nfrom transformers import TrainingArguments,Trainer\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\nimport datasets\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom sklearn.metrics import log_loss\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:49.459504Z","iopub.execute_input":"2023-08-09T23:48:49.460143Z","iopub.status.idle":"2023-08-09T23:48:49.464856Z","shell.execute_reply.started":"2023-08-09T23:48:49.460103Z","shell.execute_reply":"2023-08-09T23:48:49.464184Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"warnings.simplefilter('ignore')\nlogging.disable(logging.WARNING)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:06.153984Z","iopub.execute_input":"2023-08-09T23:48:06.154582Z","iopub.status.idle":"2023-08-09T23:48:06.159591Z","shell.execute_reply.started":"2023-08-09T23:48:06.154543Z","shell.execute_reply":"2023-08-09T23:48:06.158461Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Defining a function to calculate the log loss score for predictions\ndef score(preds):\n    # Calculate the log loss using the label ids and softmax predictions\n    logloss = log_loss(preds.label_ids, F.softmax(torch.Tensor(preds.predictions)))\n    \n    # Return the log loss score\n    return {'log loss': logloss}","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:06.429045Z","iopub.execute_input":"2023-08-09T23:48:06.429388Z","iopub.status.idle":"2023-08-09T23:48:06.434586Z","shell.execute_reply.started":"2023-08-09T23:48:06.429348Z","shell.execute_reply":"2023-08-09T23:48:06.433641Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model_nm = '../input/classification-debert-model'","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:06.703837Z","iopub.execute_input":"2023-08-09T23:48:06.704158Z","iopub.status.idle":"2023-08-09T23:48:06.708026Z","shell.execute_reply.started":"2023-08-09T23:48:06.704120Z","shell.execute_reply":"2023-08-09T23:48:06.707292Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer\n\n# Load the trained model and tokenizer from the specified model name or path\nloaded_model = AutoModelForSequenceClassification.from_pretrained(model_nm)\nloaded_tokz = AutoTokenizer.from_pretrained(model_nm)\n\n# Define the score function for evaluation\ndef score(preds):\n    logloss = log_loss(preds.label_ids, F.softmax(torch.Tensor(preds.predictions)))\n    return {'log loss': logloss}\n\n# Set up the Trainer for prediction using the loaded model and tokenizer\nloaded_trainer = Trainer(model=loaded_model, tokenizer=loaded_tokz, compute_metrics=score)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:49:48.728109Z","iopub.execute_input":"2023-08-09T23:49:48.728721Z","iopub.status.idle":"2023-08-09T23:49:51.402294Z","shell.execute_reply.started":"2023-08-09T23:49:48.728670Z","shell.execute_reply":"2023-08-09T23:49:51.401486Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"sep = loaded_tokz.sep_token\nsep","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:49:54.008453Z","iopub.execute_input":"2023-08-09T23:49:54.009095Z","iopub.status.idle":"2023-08-09T23:49:54.013954Z","shell.execute_reply.started":"2023-08-09T23:49:54.009053Z","shell.execute_reply":"2023-08-09T23:49:54.013368Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"'[SEP]'"},"metadata":{}}]},{"cell_type":"code","source":"# Defining a function for tokenization using the loaded tokenizer\ndef tok_func(x):\n    # Tokenize the input using the loaded tokenizer with truncation\n    return loaded_tokz(x[\"inputs\"], truncation=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:49:54.355568Z","iopub.execute_input":"2023-08-09T23:49:54.356374Z","iopub.status.idle":"2023-08-09T23:49:54.360544Z","shell.execute_reply.started":"2023-08-09T23:49:54.356321Z","shell.execute_reply":"2023-08-09T23:49:54.359763Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:49:55.892194Z","iopub.execute_input":"2023-08-09T23:49:55.892820Z","iopub.status.idle":"2023-08-09T23:49:55.909024Z","shell.execute_reply.started":"2023-08-09T23:49:55.892766Z","shell.execute_reply":"2023-08-09T23:49:55.907755Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"             id discourse_type  \\\n0  0FB0700DAF44       Position   \n1  0FB0700DAF44          Claim   \n2  0FB0700DAF44          Claim   \n3  0FB0700DAF44       Evidence   \n4  0FB0700DAF44          Claim   \n5  0FB0700DAF44       Evidence   \n6  0FB0700DAF44       Evidence   \n\n                                    predictionstring  discourse_start  \\\n0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                0   \n1  67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 8...              396   \n2  186 187 188 189 190 191 192 193 194 195 196 19...             1099   \n3  213 214 215 216 217 218 219 220 221 222 223 22...             1280   \n4  303 304 305 306 307 308 309 310 311 312 313 31...             1820   \n5  339 340 341 342 343 344 345 346 347 348 349 35...             2021   \n6  403 404 405 406 407 408 409 410 411 412 413 41...             2391   \n\n   discourse_end                                     discourse_text  \\\n0            395  While it may be true that the Mason City gover...   \n1            551  Citing surveys of city residents, the author r...   \n2           1279  Additionally, the author implies that resident...   \n3           1819  While a polluted, smelly river would likely cu...   \n4           2020  Building upon the implication that residents d...   \n5           2390  If the river's water quality and smell result ...   \n6           2630  There are some bodies of water which emit a st...   \n\n   discourse_id                                             inputs  \n0             0  Position[SEP]While it may be true that the Mas...  \n1             1  Claim[SEP]Citing surveys of city residents, th...  \n2             2  Claim[SEP]Additionally, the author implies tha...  \n3             3  Evidence[SEP]While a polluted, smelly river wo...  \n4             4  Claim[SEP]Building upon the implication that r...  \n5             5  Evidence[SEP]If the river's water quality and ...  \n6             6  Evidence[SEP]There are some bodies of water wh...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_type</th>\n      <th>predictionstring</th>\n      <th>discourse_start</th>\n      <th>discourse_end</th>\n      <th>discourse_text</th>\n      <th>discourse_id</th>\n      <th>inputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0FB0700DAF44</td>\n      <td>Position</td>\n      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n      <td>0</td>\n      <td>395</td>\n      <td>While it may be true that the Mason City gover...</td>\n      <td>0</td>\n      <td>Position[SEP]While it may be true that the Mas...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 8...</td>\n      <td>396</td>\n      <td>551</td>\n      <td>Citing surveys of city residents, the author r...</td>\n      <td>1</td>\n      <td>Claim[SEP]Citing surveys of city residents, th...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>186 187 188 189 190 191 192 193 194 195 196 19...</td>\n      <td>1099</td>\n      <td>1279</td>\n      <td>Additionally, the author implies that resident...</td>\n      <td>2</td>\n      <td>Claim[SEP]Additionally, the author implies tha...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>213 214 215 216 217 218 219 220 221 222 223 22...</td>\n      <td>1280</td>\n      <td>1819</td>\n      <td>While a polluted, smelly river would likely cu...</td>\n      <td>3</td>\n      <td>Evidence[SEP]While a polluted, smelly river wo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>303 304 305 306 307 308 309 310 311 312 313 31...</td>\n      <td>1820</td>\n      <td>2020</td>\n      <td>Building upon the implication that residents d...</td>\n      <td>4</td>\n      <td>Claim[SEP]Building upon the implication that r...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>339 340 341 342 343 344 345 346 347 348 349 35...</td>\n      <td>2021</td>\n      <td>2390</td>\n      <td>If the river's water quality and smell result ...</td>\n      <td>5</td>\n      <td>Evidence[SEP]If the river's water quality and ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>403 404 405 406 407 408 409 410 411 412 413 41...</td>\n      <td>2391</td>\n      <td>2630</td>\n      <td>There are some bodies of water which emit a st...</td>\n      <td>6</td>\n      <td>Evidence[SEP]There are some bodies of water wh...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['inputs'] = df.discourse_type + sep + df.discourse_text","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:48:10.338778Z","iopub.execute_input":"2023-08-09T23:48:10.339242Z","iopub.status.idle":"2023-08-09T23:48:10.351159Z","shell.execute_reply.started":"2023-08-09T23:48:10.339180Z","shell.execute_reply":"2023-08-09T23:48:10.349938Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries\nfrom datasets import Dataset\n\n# Defining a function to create a tokenized dataset\ndef get_dds(df, train=True):\n    # Creating a Dataset object from the provided DataFrame\n    ds = Dataset.from_pandas(df)\n    \n    # Columns to remove from the dataset before tokenization\n    to_remove = ['discourse_text', 'discourse_type', 'inputs', 'discourse_id', 'id', 'predictionstring', 'discourse_start', 'discourse_end']\n    \n    # Applying the tokenization function to the dataset using map\n    tok_ds = ds.map(tok_func, batched=True, remove_columns=to_remove)\n    \n    # Returning the tokenized dataset\n    return tok_ds\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:50:17.225851Z","iopub.execute_input":"2023-08-09T23:50:17.226227Z","iopub.status.idle":"2023-08-09T23:50:17.232998Z","shell.execute_reply.started":"2023-08-09T23:50:17.226171Z","shell.execute_reply":"2023-08-09T23:50:17.231836Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Creating a tokenized dataset for testing using the provided function\nloaded_test_ds = get_dds(df, train=False)\n\n# Using the loaded trainer to predict labels and getting softmax predictions\nloaded_predictions = loaded_trainer.predict(loaded_test_ds)\nloaded_softmax_preds = F.softmax(torch.Tensor(loaded_predictions.predictions)).numpy().astype(float)\n\n# Storing the softmax predictions\nloaded_preds = loaded_softmax_preds\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:50:42.833359Z","iopub.execute_input":"2023-08-09T23:50:42.833703Z","iopub.status.idle":"2023-08-09T23:50:45.414201Z","shell.execute_reply.started":"2023-08-09T23:50:42.833665Z","shell.execute_reply":"2023-08-09T23:50:45.413464Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb7f2a364f2b47dd980eb07aeda29b16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"# Creating a new DataFrame to store the final results\nfinal_df = pd.DataFrame()\n\n# Copying the relevant columns from the original DataFrame to the new DataFrame\nfinal_df['id'] = df['id']\nfinal_df['discourse_type'] = df['discourse_type']\nfinal_df['discourse_start'] = df['discourse_start']\nfinal_df['discourse_end'] = df['discourse_end']\n\n# Adding columns for prediction probabilities for each class\nfinal_df['Ineffective'] = loaded_preds[:, 0]  # Probability for class 'Ineffective'\nfinal_df['Adequate'] = loaded_preds[:, 1]      # Probability for class 'Adequate'\nfinal_df['Effective'] = loaded_preds[:, 2]     # Probability for class 'Effective'\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:50:54.524012Z","iopub.execute_input":"2023-08-09T23:50:54.524980Z","iopub.status.idle":"2023-08-09T23:50:54.536683Z","shell.execute_reply.started":"2023-08-09T23:50:54.524920Z","shell.execute_reply":"2023-08-09T23:50:54.534889Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Function to determine the highest effectiveness level for a row\ndef get_effectiveness(row):\n    # Find the maximum effectiveness probability among the classes\n    max_effectiveness = max(row['Ineffective'], row['Adequate'], row['Effective'])\n    \n    # Check which class has the maximum probability and return the corresponding label\n    if row['Ineffective'] == max_effectiveness:\n        return f\"{row['discourse_type']} - Ineffective\"\n    elif row['Adequate'] == max_effectiveness:\n        return f\"{row['discourse_type']} - Adequate\"\n    else:\n        return f\"{row['discourse_type']} - Effective\"\n\n# Apply the get_effectiveness function to create the \"Effectiveness\" column\nfinal_df['Effectiveness'] = final_df.apply(get_effectiveness, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:51:42.341574Z","iopub.execute_input":"2023-08-09T23:51:42.342797Z","iopub.status.idle":"2023-08-09T23:51:42.352478Z","shell.execute_reply.started":"2023-08-09T23:51:42.342742Z","shell.execute_reply":"2023-08-09T23:51:42.351136Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"final_df","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:51:42.677659Z","iopub.execute_input":"2023-08-09T23:51:42.678194Z","iopub.status.idle":"2023-08-09T23:51:42.692935Z","shell.execute_reply.started":"2023-08-09T23:51:42.678133Z","shell.execute_reply":"2023-08-09T23:51:42.692231Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"             id discourse_type  discourse_start  discourse_end  Ineffective  \\\n0  0FB0700DAF44       Position                0            395     0.275402   \n1  0FB0700DAF44          Claim              396            551     0.275179   \n2  0FB0700DAF44          Claim             1099           1279     0.275024   \n3  0FB0700DAF44       Evidence             1280           1819     0.275675   \n4  0FB0700DAF44          Claim             1820           2020     0.275519   \n5  0FB0700DAF44       Evidence             2021           2390     0.275520   \n6  0FB0700DAF44       Evidence             2391           2630     0.275595   \n\n   Adequate  Effective        Effectiveness  \n0  0.379183   0.345415  Position - Adequate  \n1  0.378909   0.345913     Claim - Adequate  \n2  0.379236   0.345740     Claim - Adequate  \n3  0.378131   0.346194  Evidence - Adequate  \n4  0.378799   0.345682     Claim - Adequate  \n5  0.378569   0.345910  Evidence - Adequate  \n6  0.378632   0.345773  Evidence - Adequate  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_type</th>\n      <th>discourse_start</th>\n      <th>discourse_end</th>\n      <th>Ineffective</th>\n      <th>Adequate</th>\n      <th>Effective</th>\n      <th>Effectiveness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0FB0700DAF44</td>\n      <td>Position</td>\n      <td>0</td>\n      <td>395</td>\n      <td>0.275402</td>\n      <td>0.379183</td>\n      <td>0.345415</td>\n      <td>Position - Adequate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>396</td>\n      <td>551</td>\n      <td>0.275179</td>\n      <td>0.378909</td>\n      <td>0.345913</td>\n      <td>Claim - Adequate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>1099</td>\n      <td>1279</td>\n      <td>0.275024</td>\n      <td>0.379236</td>\n      <td>0.345740</td>\n      <td>Claim - Adequate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>1280</td>\n      <td>1819</td>\n      <td>0.275675</td>\n      <td>0.378131</td>\n      <td>0.346194</td>\n      <td>Evidence - Adequate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0FB0700DAF44</td>\n      <td>Claim</td>\n      <td>1820</td>\n      <td>2020</td>\n      <td>0.275519</td>\n      <td>0.378799</td>\n      <td>0.345682</td>\n      <td>Claim - Adequate</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>2021</td>\n      <td>2390</td>\n      <td>0.275520</td>\n      <td>0.378569</td>\n      <td>0.345910</td>\n      <td>Evidence - Adequate</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0FB0700DAF44</td>\n      <td>Evidence</td>\n      <td>2391</td>\n      <td>2630</td>\n      <td>0.275595</td>\n      <td>0.378632</td>\n      <td>0.345773</td>\n      <td>Evidence - Adequate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"colors = {\n            'Lead - Ineffective': '#8000ff',\n            'Lead - Adequate': '#8000ff',\n            'Lead - Effective': '#8000ff',\n            'Position - Ineffective': '#2b7ff6',\n            'Position - Adequate': '#2b7ff6',\n            'Position - Effective': '#2b7ff6',\n            'Evidence - Ineffective': '#2adddd',\n            'Evidence - Adequate': '#2adddd',\n            'Evidence - Effective': '#2adddd',\n            'Claim - Ineffective': '#80ffb4',\n            'Claim - Adequate': '#80ffb4',\n            'Claim - Effective': '#80ffb4',\n            'Concluding Statement - Ineffective': 'd4dd80',\n            'Concluding Statement - Adequate': 'd4dd80',\n            'Concluding Statement - Effective': 'd4dd80',\n            'Counterclaim - Ineffective': '#ff8042',\n            'Counterclaim - Adequate': '#ff8042',\n            'Counterclaim - Effective': '#ff8042',\n            'Rebuttal - Ineffective': '#ff0000',\n            'Rebuttal - Adequate': '#ff0000',\n            'Rebuttal - Effective': '#ff0000'\n         }\n\n# Defining a function to visualize labeled spans in text\ndef visualize(example):\n    ents = []\n    \n    # Iterating through rows of the final_df DataFrame for the specified example\n    for i, row in final_df[final_df['id'] == example].iterrows():\n        ents.append({\n            'start': int(row['discourse_start']),\n            'end': int(row['discourse_end']),\n            'label': row['Effectiveness']\n        })\n\n    # Assuming txt contains the text for visualization\n    data = txt\n    \n    # Creating a document structure for visualization\n    doc2 = {\n        \"text\": data,\n        \"ents\": ents,\n        \"title\": 'Argument Essay:'\n    }\n\n    # Defining options for visualization, including labels and colors\n    options = {\"ents\": final_df.Effectiveness.unique().tolist(), \"colors\": colors}\n    \n    # Rendering the entity visualization using spaCy's displacy\n    displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:52:55.563271Z","iopub.execute_input":"2023-08-09T23:52:55.564237Z","iopub.status.idle":"2023-08-09T23:52:55.575565Z","shell.execute_reply.started":"2023-08-09T23:52:55.564167Z","shell.execute_reply":"2023-08-09T23:52:55.574520Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"from spacy import displacy\n\n# Get the list of example IDs from the final_df DataFrame\nexamples = final_df['id'].values.tolist()\n\n# Create a set to keep track of visualized IDs\nvisualized_ids = set()\n\n# Loop through each example ID\nfor ex in examples:\n    # Check if the ID hasn't been visualized yet\n    if ex not in visualized_ids:\n        # Call the visualize function to create the visualization\n        visualize(ex)\n        print('\\n')  # Print a newline for separation\n        # Add the visualized ID to the set\n        visualized_ids.add(ex)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T23:53:21.869102Z","iopub.execute_input":"2023-08-09T23:53:21.869436Z","iopub.status.idle":"2023-08-09T23:53:21.881294Z","shell.execute_reply.started":"2023-08-09T23:53:21.869401Z","shell.execute_reply":"2023-08-09T23:53:21.880293Z"},"trusted":true},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">Argument Essay:</h2>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    While it may be true that the Mason City government ought to devote more money to riverside recreational facilities, this author's argument does not make a cogent case for increased resources based on river use. It is easy to understand why city residents would want a cleaner river, but this argument is rife with holes and assumptions, and thus, not strong enough to lead to increased funding.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position - Adequate</span>\n</mark>\n</br>\n<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Citing surveys of city residents, the author reports city resident's love of water sports. It is not clear, however, the scope and validity of that survey.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim - Adequate</span>\n</mark>\n For example, the survey could have asked residents if they prefer using the river for water sports or would like to see a hydroelectric dam built, which may have swayed residents toward river sports. The sample may not have been representative of city residents, asking only those residents who live upon the river. The survey may have been 10 pages long, with 2 questions dedicated to river sports. We just do not know. Unless the survey is fully representative, valid, and reliable, it can not be used to effectively back the author's argument.</br>\n<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Additionally, the author implies that residents do not use the river for swimming, boating, and fishing, despite their professed interest, because the water is polluted and smelly.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim - Adequate</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    While a polluted, smelly river would likely cut down on river sports, a concrete connection between the resident's lack of river use and the river's current state is not effectively made. Though there have been complaints, we do not know if there have been numerous complaints from a wide range of people, or perhaps from one or two individuals who made numerous complaints. To strengthen his/her argument, the author would benefit from implementing a normed survey asking a wide range of residents why they do not currently use the river.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence - Adequate</span>\n</mark>\n</br>\n<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Building upon the implication that residents do not use the river due to the quality of the river's water and the smell, the author suggests that a river clean up will result in increased river usage.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim - Adequate</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    If the river's water quality and smell result from problems which can be cleaned, this may be true. For example, if the decreased water quality and aroma is caused by pollution by factories along the river, this conceivably could be remedied. But if the quality and\naroma results from the natural mineral deposits in the water or surrounding rock, this may not be true.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence - Adequate</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    There are some bodies of water which emit a strong smell of sulphur due to the geography of the area. This is not something likely to be affected by a clean-up. Consequently, a river clean up may have no impact upon river usage. Regardless\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence - Adequate</span>\n</mark>\n of whether the river's quality is able to be improved or not, the author does not effectively show a connection between water quality and river usage.</br>A clean, beautiful, safe river often adds to a city's property values, leads to increased tourism and revenue from those who come to take advantage of the river, and a better overall quality of life for residents. For these reasons, city government may decide to invest in improving riverside recreational facilities.</br>However, this author's argument is not likely significantly persuade the city goverment to allocate increased funding.</br></div></span>"},"metadata":{}},{"name":"stdout","text":"\n\n","output_type":"stream"}]}]}